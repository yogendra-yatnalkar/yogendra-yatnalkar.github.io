<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>GenAI on Yogendra Y.</title>
    <link>https://yogendra-yatnalkar.github.io/tags/genai.html</link>
    <description>Recent content in GenAI on Yogendra Y.</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://yogendra-yatnalkar.github.io/tags/genai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Claude Sonnet Drives in GTA San Andreas</title>
      <link>https://yogendra-yatnalkar.github.io/side-projects/vlm-drives-in-gta.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://yogendra-yatnalkar.github.io/side-projects/vlm-drives-in-gta.html</guid>
      <description>VLM (Claude v3 Sonnet) Drives in GTA San Andreas (Exp1)#AI Video Generation for: Story of Shepherd Boy and the Wolf#Github Link: https://github.com/yogendra-yatnalkar/VLM-drives-in-GTALast Edited: 05/08/2024
Youtube Video#/
Description:#Trying to play with Anthropic Claude V3 (Haiku and Sonnet). My theory is that these VLM&amp;rsquo;s are quite good in deciding how to drive based on current input frame and the past actions. Need to confirm the hypothesis.</description>
    </item>
    
    <item>
      <title>AI Assisted Video Generation with White-Board Animations</title>
      <link>https://yogendra-yatnalkar.github.io/side-projects/ai-assisted-video-generation.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://yogendra-yatnalkar.github.io/side-projects/ai-assisted-video-generation.html</guid>
      <description>AI Assisted Video Generation with White-Board Animations#AI Video Generation for: Story of Shepherd Boy and the Wolf#Github Link: https://github.com/yogendra-yatnalkar/storyboard-aiLast Edited: 06/01/2024
Youtube Video#HOW THE VIDEO WAS MADE ?#The story was taken from internet. A 4 line summary of the story was generated using ChatGPT For each summary line, a corresponding image was generated using Stable Diffusion In each image (4 in our case), the important object were masked using MetaAI SAM I have developed a custom image to white-board animation code which converted the images to videos (This was the most time-consuming part of the development process).</description>
    </item>
    
  </channel>
</rss>
