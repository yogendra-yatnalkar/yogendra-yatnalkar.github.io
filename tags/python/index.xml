<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on Yogendra Y.</title>
    <link>https://yogendra-yatnalkar.github.io/tags/python.html</link>
    <description>Recent content in Python on Yogendra Y.</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://yogendra-yatnalkar.github.io/tags/python/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Promptless Task-Specific Finetuning of MetaAI Segment-Anything</title>
      <link>https://yogendra-yatnalkar.github.io/blogs/promptless-taskspecific-finetuning-segment-anything.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://yogendra-yatnalkar.github.io/blogs/promptless-taskspecific-finetuning-segment-anything.html</guid>
      <description>Promptless Task-Specific Finetuning of MetaAI Segment-Anything#Date: January 01, 2024#NOTE:#The NB was originally developed on Kaggle: https://www.kaggle.com/code/yogendrayatnalkar/promptless-taskspecific-finetuning-of-metaai-samRelated Github Repository: https://github.com/yogendra-yatnalkar/SAM-Promptless-Task-Specific-Finetuning/tree/mainTask#Finetune SAM model on Custom dataset to segment objects without prompts (during training and inference)#Approach#How does SAM work (high-level):#Sam Encoder &amp;ndash;&amp;gt; ViT + Neck-Module (Consisting of 2 Conv2D layers used for downsampling the channels of the ViT output) The Encoder ViT has a patch-size of 16x16.</description>
    </item>
    
    <item>
      <title>Meta-AI SAM: AutoMatic Semantic Segmentation</title>
      <link>https://yogendra-yatnalkar.github.io/blogs/sam-automatic-semantic-segmentation.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://yogendra-yatnalkar.github.io/blogs/sam-automatic-semantic-segmentation.html</guid>
      <description>Meta-AI SAM: AutoMatic Semantic Segmentation#Date: November 26, 2023#NOTE:#The NB was originally developed on Kaggle: https://www.kaggle.com/code/yogendrayatnalkar/finetuning-segment-anythingRelated Github Repository: https://github.com/yogendra-yatnalkar/SAM-Automatic-Semantic-SegmentationTask:#Semantically segment objects from image AUTOMATICALLY with the help of META AI SAM, without PROMPTS/TRAINING#Segment all the pepperoni pieces from the pizza topping#Approach:#1. Automatic Mask Generation (AMG)
Utilizing the Segment Anything Model (SAM) from the MetaAI SAM repository, perform instance segmentation on the entire image.</description>
    </item>
    
    <item>
      <title>Backtracking AWS Lookout for Vision Service</title>
      <link>https://yogendra-yatnalkar.github.io/blogs/backtracking_aws_lookout_for_vision_service.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://yogendra-yatnalkar.github.io/blogs/backtracking_aws_lookout_for_vision_service.html</guid>
      <description>Backtracking AWS Lookout For Vision Service#The article tries to trace back AWS Lookout for Vision: Edge service model and successfully custom loads the model for inference (Just imagine the reduced inference cost ðŸ”¥)
Co-Author:Â Palash NimodiaDate: June 23, 2022
Medium Link: https://medium.com/@yogenyat/backtracking-aws-lookout-for-vision-service-136c47c85168Introduction:#NOTE for the reader: Its fine if you have not used AWS Lookout For Vision service before, but if you are interested in knowing how we can back-track a managed service (if possible ðŸ™ˆ), you are at the right place.</description>
    </item>
    
  </channel>
</rss>
