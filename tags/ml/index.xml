<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ML on Yogendra Y.</title>
    <link>https://yogendra-yatnalkar.github.io/tags/ml.html</link>
    <description>Recent content in ML on Yogendra Y.</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://yogendra-yatnalkar.github.io/tags/ml/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>End-to-End MLOps on AWS (3 blogs)</title>
      <link>https://yogendra-yatnalkar.github.io/blogs/end-to-end-mlops-on-aws.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://yogendra-yatnalkar.github.io/blogs/end-to-end-mlops-on-aws.html</guid>
      <description>End-to-End MLOps on AWS: Blog Series#Last Edit Date: December 26, 2023
I had co-authored 3 blogs out of 7 blogs in total on the topic: &amp;ldquo;End-to-End MLOps on AWS&amp;rdquo;. The blog series is hosted on Quantiphi&amp;rsquo;s Medium Account Other than Quantiphi&amp;rsquo;s Medium account, the blogs are also hosted seperately on github as follows:
https://sagemaker-mlops-samples.github.io/#Authors of the below 3 blogs:
Palash Nimodia(Architect â€” Machine Learning)</description>
    </item>
    
    <item>
      <title>Claude Sonnet Drives in GTA San Andreas</title>
      <link>https://yogendra-yatnalkar.github.io/side-projects/vlm-drives-in-gta.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://yogendra-yatnalkar.github.io/side-projects/vlm-drives-in-gta.html</guid>
      <description>VLM (Claude v3 Sonnet) Drives in GTA San Andreas (Exp1)#AI Video Generation for: Story of Shepherd Boy and the Wolf#Github Link: https://github.com/yogendra-yatnalkar/VLM-drives-in-GTALast Edited: 05/08/2024
Youtube Video#/
Description:#Trying to play with Anthropic Claude V3 (Sonnet). My theory is that these VLM&amp;rsquo;s can be quite good in deciding how to drive based on current input frame and the past actions. Need to confirm the hypothesis.</description>
    </item>
    
    <item>
      <title>AI Assisted Video Generation with White-Board Animations</title>
      <link>https://yogendra-yatnalkar.github.io/side-projects/ai-assisted-video-generation.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://yogendra-yatnalkar.github.io/side-projects/ai-assisted-video-generation.html</guid>
      <description>AI Assisted Video Generation with White-Board Animations#AI Video Generation for: Story of Shepherd Boy and the Wolf#Github Link: https://github.com/yogendra-yatnalkar/storyboard-aiLast Edited: 06/01/2024
Youtube Video#HOW THE VIDEO WAS MADE ?#The story was taken from internet. A 4 line summary of the story was generated using ChatGPT For each summary line, a corresponding image was generated using Stable Diffusion In each image (4 in our case), the important object were masked using MetaAI SAM I have developed a custom image to white-board animation code which converted the images to videos (This was the most time-consuming part of the development process).</description>
    </item>
    
  </channel>
</rss>
