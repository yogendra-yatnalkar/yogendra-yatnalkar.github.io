<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>CV on Yogendra Y.</title>
    <link>https://yogendra-yatnalkar.github.io/notes/cv.html</link>
    <description>Recent content in CV on Yogendra Y.</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://yogendra-yatnalkar.github.io/notes/cv/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>SAM-Segment-Anything</title>
      <link>https://yogendra-yatnalkar.github.io/notes/cv/sam-segment-anything.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://yogendra-yatnalkar.github.io/notes/cv/sam-segment-anything.html</guid>
      <description>Segment Anything (SAM)#Last Edited 16/07/2023 Source: - Original Paper (notes till page no 7) - Youtube:Â https://www.youtube.com/watch?v=eYhvJR4zFUM Introduction:#Foundation model for segmentation.
Important thing to note here, is that SAM is not just for semantic segmentation but can also be used for instance or panoptic or salient segmentation as well. We just need to engineer it accordingly.
Trained ON: 11 million images and 1 billion corresponding masks</description>
    </item>
    
    <item>
      <title>SegFormer: Segmentation using Transformer</title>
      <link>https://yogendra-yatnalkar.github.io/notes/cv/segformer.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://yogendra-yatnalkar.github.io/notes/cv/segformer.html</guid>
      <description>SegFormer: Segmentation using Transformer#Last Edited 16/07/2023 Source: SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers - YouTubeInput patch size: 4x4
In ViT, it was 16x16, but with smaller path size, the authors said, smaller batch size is better (and required) for dense prediction.
Note: With reducing the patch size, the computation increases.
After each transformer block (encoder in this case), there is a feed-forward block which is mainly used to lower the dimension like older UNet &amp;ndash;&amp;gt; i.</description>
    </item>
    
    <item>
      <title>Self Supervised Learning</title>
      <link>https://yogendra-yatnalkar.github.io/notes/cv/self-supervised-learning.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://yogendra-yatnalkar.github.io/notes/cv/self-supervised-learning.html</guid>
      <description>A Cookbook of Self-Supervised Learning:#Initial Notes from: https://arxiv.org/abs/2304.12210 Intro:#NLP advanced due to SSL &amp;ndash;&amp;gt; No need of labelled data to train supervised model
SSL -&amp;gt; Define a pretext task &amp;ndash;&amp;gt; Un-labelled data &amp;ndash;&amp;gt; intelligent representation
NLP: Word2Vec is SSL &amp;ndash; In a sentence, mask a word and predict the surrounding words (It learns context)
CV: 2 current popular ways:
mask a patch and prediction of masked path</description>
    </item>
    
    <item>
      <title>Stable Diffusion Notes</title>
      <link>https://yogendra-yatnalkar.github.io/notes/cv/stable-diffusion.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://yogendra-yatnalkar.github.io/notes/cv/stable-diffusion.html</guid>
      <description>Stable Diffusion Notes#Last Edited 28/04/2024 What is generative AI: Sampling from a latent probability distribution
Latent Space: Representation of a data-item in embedding space where similar items are close-by
Joint Probability: likelihood of 2 events occurring together
Conditional Prob: For two events A,B: Prob of event B when event A has occurred Marginalized Prob: For a joint prob between event A and B, what is the prob of event A irrespective of prob of event B Lets say all possible value of event B are: B1, B2,&amp;hellip;.</description>
    </item>
    
  </channel>
</rss>
