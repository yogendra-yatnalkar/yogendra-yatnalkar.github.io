<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Yogendra Y.</title>
    <link>https://yogendra-yatnalkar.github.io/notes/general.html</link>
    <description>Recent content on Yogendra Y.</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://yogendra-yatnalkar.github.io/notes/general/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Benchmarking Inference with Torchserve</title>
      <link>https://yogendra-yatnalkar.github.io/notes/general/benchmarking-with-torchserve.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://yogendra-yatnalkar.github.io/notes/general/benchmarking-with-torchserve.html</guid>
      <description>Benchmarking Inference with Torchserve#Last Edited 24/12/2023 Pytorch default - g4dn.xlarge#Notes:#Instance Type: ml.g4dn.xlarge
GPU: Nvidia T4 vCPU no: 4 CPU memory: 16 GB GPU memory: 16 GB Max RPS achieved: 32
With various different configuration ranging from min/max worker = 1 to 4 and batch-size 4 to 32, the max RPS possible was only 32. Locust Configuration: Max Users: 200, Spawn Rate: 10 Max Response time at 95th percentile: ~5-6 sec</description>
    </item>
    
    <item>
      <title>General Notes</title>
      <link>https://yogendra-yatnalkar.github.io/notes/general/general-general.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://yogendra-yatnalkar.github.io/notes/general/general-general.html</guid>
      <description>Linux:#Wget vs Curl#curl and wget both support http and various types of FTP protocols. curl is library but wget is a CLI tool. curl is used for both way data transfer (src to detination and vice-versa) But, wget can be used only for single way data transfer, example: downloading something form a web-server. </description>
    </item>
    
    <item>
      <title>Kullback-Leibler Divergence (KL Divergence)</title>
      <link>https://yogendra-yatnalkar.github.io/notes/general/kl-divergence.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://yogendra-yatnalkar.github.io/notes/general/kl-divergence.html</guid>
      <description>Kullback-Leibler Divergence (KL Divergence)#Last Edited 25/06/2023 Definition:#Measures the distance between 2 prabability distributions Explanation + Proof:#Base Video: Intuitively Understanding the KL Divergence - YouTubeSequence of flips: H -&amp;gt; H -&amp;gt; T &amp;hellip;..
Multiply the probabilities from both the coins for the corresponding heads and tails. It is nothing but:
for True coin: P1 raise to something and P2 raise to something else</description>
    </item>
    
    <item>
      <title>Model Serving</title>
      <link>https://yogendra-yatnalkar.github.io/notes/general/model-serving.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://yogendra-yatnalkar.github.io/notes/general/model-serving.html</guid>
      <description>Notes on Model Serving#Example: Torchserve, Tf-Serving, Triton, Flask, etc
TorchServe: - to check model status, I am using port 8081 - for inference, I am using port 8080 - if not using ts-config while deploying a model, it generates error - Question: - when to use 8080 vs 8081 &amp;ndash;&amp;gt; Inference api is bind to 8080, management api is bind to 8081 - how to load test ?</description>
    </item>
    
    <item>
      <title>Un-Answered Questions</title>
      <link>https://yogendra-yatnalkar.github.io/notes/general/unanswered-questions.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://yogendra-yatnalkar.github.io/notes/general/unanswered-questions.html</guid>
      <description>Un-Answered Questions:#Difference between Float16 vs Bfloat16 vs Tensor-Float16 ?
Vector Databases: HNSW vs IVF ?
Difference between vector DB&amp;rsquo;s and FAISS library (by Meta) ?
From my current knowledge both are same, but then why is everyone behind vector DB&amp;rsquo;s instead of using FAISS directly ? Null Hypothesis test &amp;raquo; p-values &amp;raquo; calculated using t-test or z-test
Weeb Union Umar Jamil Cohehre&amp;rsquo;s embedding v3
RetNet &amp;ndash;&amp;gt; Saw it on high note &amp;ndash;&amp;gt; Removes the softmax from the Transformer network and adds a exponential-moving-average-weights to the network by which it gives more importance to the recent tokens</description>
    </item>
    
    <item>
      <title>Vector Search and Stores</title>
      <link>https://yogendra-yatnalkar.github.io/notes/general/vector-store-and-search.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://yogendra-yatnalkar.github.io/notes/general/vector-store-and-search.html</guid>
      <description>Note: Just putting down few notes from AWS partner-cast session
Vector Search and Vector Stores#How to measure similarity in embeddings?#Cosine Similarity: Gives the angle between the 2 embeddings. Higher the angle, bigger is the difference between 2 embeddings.
Dot-Product: Same as cosine similarity but gives us the magnitude between 2 vectors instead of direction/angle.
Real-life Use cases:#Semantic search
Recommendation System
Anomaly detection and pattern recognition</description>
    </item>
    
    <item>
      <title>Web-API performance improvement</title>
      <link>https://yogendra-yatnalkar.github.io/notes/general/api-performance-improvement.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://yogendra-yatnalkar.github.io/notes/general/api-performance-improvement.html</guid>
      <description>API Performance Improvement#Based on: Top 7 Ways to 10x Your API Performance - YouTubeOptimization should not be the first step of development
1. Caching:#If same request is repeated multiple times &amp;ndash;&amp;gt; cache hence no need to recompute or hit the DB again.
For DB, its: MemCacheD or Redis
2. Connection Pooling:#Having continues connections with DB can slow down server as each connection requires a lot of handshake protocol.</description>
    </item>
    
  </channel>
</rss>
