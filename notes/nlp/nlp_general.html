<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="NLP General:#I will keep on appending stuff which I read about NLP as and when I get time in this place This is mainly intended for two things: Quick glance on what I had read in past for a given topic If needed to deep-dive, just look at the sources I used while reading it for the first time Hackers Guide to Language Model:#Source: A Hackers&#39; Guide to Language Models - YouTubeNotebook: GitHub - fastai/lm-hackers: Hackers&#39; Guide to Language ModelsDate: 02/11/2023">
<meta name="theme-color" content="#FFFFFF">
<meta name="color-scheme" content="light dark"><meta property="og:title" content="NLP-General" />
<meta property="og:description" content="NLP General:#I will keep on appending stuff which I read about NLP as and when I get time in this place This is mainly intended for two things: Quick glance on what I had read in past for a given topic If needed to deep-dive, just look at the sources I used while reading it for the first time Hackers Guide to Language Model:#Source: A Hackers&#39; Guide to Language Models - YouTubeNotebook: GitHub - fastai/lm-hackers: Hackers&#39; Guide to Language ModelsDate: 02/11/2023" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://yogendra-yatnalkar.github.io/notes/nlp/nlp_general.html" /><meta property="article:section" content="notes" />


<title>NLP-General | Yogendra Y.</title>
<link rel="manifest" href="/manifest.json">
<link rel="icon" href="/favicon.png" type="image/x-icon">
<link rel="stylesheet" href="/book.min.0933d5ebbed8c08a206e6d3b23fee14140516cfe9ea419244eaae5e9a0f2173e.css" integrity="sha256-CTPV677YwIogbm07I/7hQUBRbP6epBkkTqrl6aDyFz4=" crossorigin="anonymous">
  <script defer src="/flexsearch.min.js"></script>
  <script defer src="/en.search.min.5c85f6422858c6aedd71596ace91087287841480563b173d8a042500d9d96a5f.js" integrity="sha256-XIX2QihYxq7dcVlqzpEIcoeEFIBWOxc9igQlANnZal8=" crossorigin="anonymous"></script>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-DTLBL509Z2"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-DTLBL509Z2', { 'anonymize_ip': false });
}
</script>
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  
</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/"><img src="/logo.png" alt="Logo" /><span>Yogendra Y.</span>
  </a>
</h2>


<div class="book-search">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>












  

  



  
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-8c14ab2d8aecfbedfb55fbca3bdb6a6b" class="toggle"  />
    <label for="section-8c14ab2d8aecfbedfb55fbca3bdb6a6b" class="flex justify-between">
      <a href="/blogs.html" class="">Blogs</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/blogs/promptless-taskspecific-finetuning-segment-anything.html" class="">Promptless Task-Specific Finetuning of MetaAI Segment-Anything</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/blogs/end-to-end-mlops-on-aws.html" class="">End-to-End MLOps on AWS (3 blogs)</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/blogs/sam-automatic-semantic-segmentation.html" class="">Meta-AI SAM: AutoMatic Semantic Segmentation</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/blogs/backtracking_aws_lookout_for_vision_service.html" class="">Backtracking AWS Lookout for Vision Service</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/blogs/finding-nth-aggregate-from-every-group-aws-athena.html" class="">Finding the nâ€™th Aggregate Value from Every Group in AWS Athena/Presto</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-ef46fe0aac274900fefdd5e564e236b2" class="toggle" checked />
    <label for="section-ef46fe0aac274900fefdd5e564e236b2" class="flex justify-between">
      <a role="button" class="">Notes</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/notes/daily-scribble.html" class="">Daily-Scribble-2024</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-97f68e7cac7678f1405673189f8b189f" class="toggle"  />
    <label for="section-97f68e7cac7678f1405673189f8b189f" class="flex justify-between">
      <a role="button" class="">General</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/notes/general/benchmarking-with-torchserve.html" class="">Benchmarking Inference with Torchserve</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/notes/general/dsa.html" class="">DSA Basic Notes:</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/notes/general/evidence-lower-bound-elbo.html" class="">ELBO: Evidence Lower Bound</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/notes/general/general-general.html" class="">General Notes</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/notes/general/kl-divergence.html" class="">Kullback-Leibler Divergence (KL Divergence)</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/notes/general/model-serving.html" class="">Model Serving</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/notes/general/random-forest.html" class="">Random Forest Notes</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/notes/general/sql.html" class="">SQL</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/notes/general/unanswered-questions.html" class="">Un-Answered Questions</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/notes/general/vector-store-and-search.html" class="">Vector Search and Stores</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/notes/general/api-performance-improvement.html" class="">Web-API performance improvement</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-9a03a2b641627d6ec5d4b7e484a1675b" class="toggle"  />
    <label for="section-9a03a2b641627d6ec5d4b7e484a1675b" class="flex justify-between">
      <a role="button" class="">AWS</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/notes/aws/aws-general.html" class="">AWS General</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-8314eced0a8c88614b1d2f53940330d5" class="toggle"  />
    <label for="section-8314eced0a8c88614b1d2f53940330d5" class="flex justify-between">
      <a role="button" class="">CV</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/notes/cv/sam-segment-anything.html" class="">SAM-Segment-Anything</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/notes/cv/segformer.html" class="">SegFormer: Segmentation using Transformer</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/notes/cv/self-supervised-learning.html" class="">Self Supervised Learning</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/notes/cv/stable-diffusion.html" class="">Stable Diffusion Notes</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-5bf3042abef6b7e58a1750f2ab25ff7e" class="toggle" checked />
    <label for="section-5bf3042abef6b7e58a1750f2ab25ff7e" class="flex justify-between">
      <a role="button" class="">NLP</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/notes/nlp/bert.html" class="">BERT</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/notes/nlp/nlp_general.html" class="active">NLP-General</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/notes/nlp/transformers_at_training_vs_inference.html" class="">Transformers at Training vs Inference</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/resume/" class="">Resume</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-77dedc5429a7c70061bd8ace32d09bfc" class="toggle"  />
    <label for="section-77dedc5429a7c70061bd8ace32d09bfc" class="flex justify-between">
      <a href="/side-projects.html" class="">Side-Projects</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/side-projects/ai-assisted-video-generation.html" class="">AI Assisted Video Generation with White-Board Animations</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>















</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <strong>NLP-General</strong>

  <label for="toc-control">
    
    <img src="/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#hackers-guide-to-language-model">Hackers Guide to Language Model:</a></li>
    <li><a href="#how-to-make-inference-faster-in-casual-language-model">How to make inference faster in Casual Language Model:</a></li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown"><h1 id="nlp-general">
  NLP General:
  <a class="anchor" href="#nlp-general">#</a>
</h1>
<ul>
<li>I will keep on appending stuff which I read about NLP as and when I get time in this place</li>
<li>This is mainly intended for two things:
<ul>
<li>Quick glance on what I had read in past for a given topic</li>
<li>If needed to deep-dive, just look at the sources I used while reading it for the first time</li>
</ul>
</li>
</ul>
<hr>
<hr>
<h2 id="hackers-guide-to-language-model">
  Hackers Guide to Language Model:
  <a class="anchor" href="#hackers-guide-to-language-model">#</a>
</h2>
<p>Source: <a href="https://www.youtube.com/watch?v=jkrNMKz9pWU" target="_blank" rel="noopener">A Hackers' Guide to Language Models - YouTube</a>
</p>
<p>Notebook: <a href="https://github.com/fastai/lm-hackers" target="_blank" rel="noopener">GitHub - fastai/lm-hackers: Hackers' Guide to Language Models</a>
</p>
<p>Date: 02/11/2023</p>
<hr>
<ul>
<li>
<p>On a high note, what is a language mode:</p>
<ul>
<li>
<p>Predicts the next word</p>
</li>
<li>
<p>or predicts the missing word</p>
</li>
</ul>
</li>
<li>
<p>Byte-Pair-Encoding tokenizer for OpenAI models: <a href="https://github.com/openai/tiktoken" target="_blank" rel="noopener">GitHub - openai/tiktoken: tiktoken is a fast BPE tokeniser for use with OpenAI's models.</a>
</p>
</li>
<li>
<p>&ldquo;NN has got the ability to create rich hierarchy of abstractions and representations on the base training data which is clearly a form of <strong>knowledge compression.</strong>&rdquo;</p>
</li>
<li>
<p><img src="https://production-media.paperswithcode.com/methods/Screen_Shot_2020-05-26_at_5.11.04_PM.png" alt="" /></p>
</li>
<li>
<p>LM&rsquo;s (mainly LLM&rsquo;s) are trained in 3 parts:</p>
<ul>
<li>
<p><em><strong>Pretrained:</strong></em> Unsupervised training on large corpus of data and building a generalized model. The tasks can be:</p>
<ul>
<li>
<p>Next word prediction</p>
</li>
<li>
<p>Mask word and predict the masked word</p>
</li>
</ul>
</li>
<li>
<p><em><strong>LLM Fine-Tuning:</strong></em> Again <strong>unsupervised training like next word prediction</strong>, but on small amount of task-specific data</p>
<ul>
<li>
<p><strong>Note</strong>: In Computer vision mainly, when we say fine-tuning, we usually train only a small part of model (usually last few layers) again. <strong>But in the case of LLM&rsquo;s, we retrain the entire Model.</strong></p>
</li>
<li>
<p>Within this second step, the paradigm has recently shifted to <strong>Instruction Finetuning</strong>. In this, the input text is of the form: <em>Instruction &ndash;&gt; Context &ndash;&gt; Question</em>. For further knowledge, a good source is: <a href="https://heidloff.net/article/instruct-tuning-large-language-models/" target="_blank" rel="noopener">Instruction Fine-tuning of Large Language Models | Niklas Heidloff</a>
</p>
</li>
<li>
<p>Llama2-chat models are instruction fine-tuned where the instruction of llama2-chat is quite long for example:</p>
<ul>
<li>
<pre tabindex="0"><code>You are a helpful, respectful and honest assistant. Always answer as helpfully 
as possible, while being safe. Your answers should not include any harmful, 
unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure 
that your responses are socially unbiased and positive in nature. If a question 
does not make any sense, or is not factually coherent, explain why instead of 
answering something not correct. If you donâ€™t know the answer to a question, 
please donâ€™t share false information.

&lt;&lt;CONTEXT&gt;&gt;

Question: &lt;&lt;Question&gt;&gt;
</code></pre></li>
</ul>
</li>
</ul>
</li>
<li>
<p><em><strong>Classifier fine-tuning:</strong></em></p>
<ul>
<li>
<p>Reinforcement Learning with Human Feedback:</p>
<ul>
<li>
<p>Good source to learn is from Yannick&rsquo;s video: <a href="https://www.youtube.com/watch?v=vLTmnaMpQCs&amp;pp=ygUUWWFubmljayBraWxjaGVyIFJMSEY%3D" target="_blank" rel="noopener">Learning to summarize from human feedback (Paper Explained) - YouTube</a>
 (This is the original paper released in 2020 by OpenAI)</p>
<ul>
<li>
<p>From my current understanding, there will be a separate scoring model</p>
</li>
<li>
<p>The LLM would generate some output for the input and scoring model will generate the score for the output.</p>
</li>
<li>
<p>The scoring model will be trained on small supervised data where the scores are generated by humans.</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>As of September 2023, GPT4 is the best SOTA LLM. Listing down few things which GPT4 cannot do:</p>
<ul>
<li>
<p>Hallucinations</p>
</li>
<li>
<p>It doesn&rsquo;t know about itself. (Why not?)  &ndash;&gt; Because it was not included in its training and due to RLHF, it is just hallucinating</p>
</li>
<li>
<p>It doesn&rsquo;t know about URLs.</p>
</li>
<li>
<p>Knowledge cutoff</p>
</li>
</ul>
</li>
<li>
<p><strong>OpenAI Cost:</strong></p>
</li>
</ul>
<p><img src="nlp_general/2023-11-02-10-18-07-image.png" alt="" /></p>
<ul>
<li>
<p><strong>Small Note on GPU Performance per price:</strong></p>
<ul>
<li>Higher priced GPU is not always as good as its price because we need GPU having ultra-fast memory transfer speed as compared to ultra-fast compute operations.</li>
</ul>
</li>
</ul>
<hr>
<hr>
<h2 id="how-to-make-inference-faster-in-casual-language-model">
  How to make inference faster in Casual Language Model:
  <a class="anchor" href="#how-to-make-inference-faster-in-casual-language-model">#</a>
</h2>
<ul>
<li>
<p>To increase performance of LLM prediction, we should try to reduce output tokens as compared to input tokens. It will have <strong>HUGE Impact</strong>.</p>
</li>
<li>
<p>KV Cache</p>
</li>
<li>
<p>Continuous Batching (different than dynamic batching)</p>
</li>
<li>
<p>Paged Attention</p>
</li>
<li>
<p>For Nvidia GPUs, use dtype: <strong>bfloat16</strong> instead of <strong>fp16</strong>. The &ldquo;blfoat16&rdquo; dtype is Nvidia Sepecfic which uses more memory but prvides faster compute.</p>
</li>
<li>
<p>Flash Attention (v2 at the time of writing) &ndash;&gt; Need to confirm if the principles of Flash-Attention are also application to non-Nvidia GPU&rsquo;s. Eg: Inferentia/TPU</p>
</li>
<li></li>
</ul>
<hr>
<hr>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">





</div>



  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments"><script src="https://utteranc.es/client.js"
        repo="yogendra-yatnalkar/yogendra-yatnalkar.github.io"
        issue-term="pathname"
        theme="preferred-color-scheme"
        crossorigin="anonymous"
        async>
</script>
</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#hackers-guide-to-language-model">Hackers Guide to Language Model:</a></li>
    <li><a href="#how-to-make-inference-faster-in-casual-language-model">How to make inference faster in Casual Language Model:</a></li>
  </ul>
</nav>


 
      </div>
    </aside>
    
  </main>

  
</body>
</html>












